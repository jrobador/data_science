{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695eaf47-ebc4-477e-b874-d7db63ce26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from data_processing import dataset_preprocessing, data_with_mask\n",
    "from sph_functions import interpolation_to_grid, hemisphere_to_spherical, spherical_to_hemisphere\n",
    "from plots_pavi import plot_sphere\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "from model import Autoencoder, initialize_model, train_autoencoder, extract_latent_space\n",
    "\n",
    "DIR = r'C:\\Github\\pavi_data'\n",
    "\n",
    "path_file   = os.path.join(DIR, '12_mean_sample_post.pt')\n",
    "path_jobs   = os.path.join(DIR, 'jobs.json')\n",
    "path_scores = os.path.join(DIR, 'scores_camcan.csv')\n",
    "n_job = 44\n",
    "\n",
    "\n",
    "net_number = None\n",
    "sh_orders = 4\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "X, y, seed = dataset_preprocessing(DEVICE, path_file, path_jobs, path_scores)\n",
    "\n",
    "vertices_left, vertices_right, network_left, network_right = data_with_mask(X, net_number)\n",
    "\n",
    "\n",
    "fancy_categories = [\n",
    "        'Benton faces',\n",
    "        'Fluid Intelligence',\n",
    "        'Emotion expression recognition',\n",
    "        'Famous faces',\n",
    "        'Hotel task',\n",
    "        'Picture priming',\n",
    "        'Proverb comprehension',\n",
    "        'Sentence comprehension (unacceptable error)',\n",
    "        'Sentence comprehension (reaction time)',\n",
    "        'Visual short term memory (mean)',\n",
    "        'Visual short term memory (precision)',\n",
    "        'Visual short term memory (doubt)',\n",
    "        'Visual short term memory (MSE)',\n",
    "    ]\n",
    "n_scores = len(fancy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3f575-e3e2-4bd9-8365-8842eea18943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh_order=4\n",
      "(218, 32258, 17)\n",
      "(218, 32258, 17)\n",
      "New shape:\n",
      "(218, 127, 254, 17)\n",
      "(218, 127, 254, 17)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "mesh_theta, sphere_src_left, sphere_src_right, sphere_dst = interpolation_to_grid(vertices_left, vertices_right, sh_orders)\n",
    "sph_data_left  = hemisphere_to_spherical(network_left, sphere_src_left, sphere_dst, sh_orders)\n",
    "sph_data_right = hemisphere_to_spherical(network_right, sphere_src_right, sphere_dst, sh_orders)\n",
    "\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)\n",
    "\n",
    "sph_data_left = sph_data_left.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_left.shape[-1])\n",
    "sph_data_right = sph_data_right.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_right.shape[-1])\n",
    "\n",
    "if isinstance(net_number, int):\n",
    "    plot_sphere(sph_data_left, net_number)\n",
    "    plot_sphere(sph_data_right, net_number)\n",
    "\n",
    "print(\"New shape:\")\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27521261-0ece-4c49-beab-18043851b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from data_processing import dataset_preprocessing, data_with_mask\n",
    "from sph_functions import interpolation_to_grid, hemisphere_to_spherical, spherical_to_hemisphere\n",
    "from plots_pavi import plot_sphere\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "from model import Autoencoder, initialize_model, train_autoencoder, extract_latent_space\n",
    "\n",
    "DIR = r'C:\\Github\\pavi_data'\n",
    "\n",
    "path_file   = os.path.join(DIR, '12_mean_sample_post.pt')\n",
    "path_jobs   = os.path.join(DIR, 'jobs.json')\n",
    "path_scores = os.path.join(DIR, 'scores_camcan.csv')\n",
    "n_job = 44\n",
    "\n",
    "\n",
    "net_number = None\n",
    "sh_orders = 16\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "X, y, seed = dataset_preprocessing(DEVICE, path_file, path_jobs, path_scores)\n",
    "\n",
    "vertices_left, vertices_right, network_left, network_right = data_with_mask(X, net_number)\n",
    "\n",
    "\n",
    "fancy_categories = [\n",
    "        'Benton faces',\n",
    "        'Fluid Intelligence',\n",
    "        'Emotion expression recognition',\n",
    "        'Famous faces',\n",
    "        'Hotel task',\n",
    "        'Picture priming',\n",
    "        'Proverb comprehension',\n",
    "        'Sentence comprehension (unacceptable error)',\n",
    "        'Sentence comprehension (reaction time)',\n",
    "        'Visual short term memory (mean)',\n",
    "        'Visual short term memory (precision)',\n",
    "        'Visual short term memory (doubt)',\n",
    "        'Visual short term memory (MSE)',\n",
    "    ]\n",
    "n_scores = len(fancy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a3c8d-c8e3-4fb2-8e4a-79bb8ab5e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh_order=16\n",
      "(218, 32258, 17)\n",
      "(218, 32258, 17)\n",
      "New shape:\n",
      "(218, 127, 254, 17)\n",
      "(218, 127, 254, 17)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "mesh_theta, sphere_src_left, sphere_src_right, sphere_dst = interpolation_to_grid(vertices_left, vertices_right, sh_orders)\n",
    "sph_data_left  = hemisphere_to_spherical(network_left, sphere_src_left, sphere_dst, sh_orders)\n",
    "sph_data_right = hemisphere_to_spherical(network_right, sphere_src_right, sphere_dst, sh_orders)\n",
    "\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)\n",
    "\n",
    "sph_data_left = sph_data_left.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_left.shape[-1])\n",
    "sph_data_right = sph_data_right.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_right.shape[-1])\n",
    "\n",
    "if isinstance(net_number, int):\n",
    "    plot_sphere(sph_data_left, net_number)\n",
    "    plot_sphere(sph_data_right, net_number)\n",
    "\n",
    "print(\"New shape:\")\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6888f34-8bbb-4727-8c0d-5f57395cabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaqu\\anaconda3\\envs\\data_science\\Lib\\site-packages\\torch\\functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3588.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "autoencoders_left  = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "autoencoders_right = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "\n",
    "for ae_l, ae_r in zip(autoencoders_left, autoencoders_right):\n",
    "    initialize_model(ae_l)\n",
    "    initialize_model(ae_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b7192-474f-4da9-b3f0-9669b49b977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Joint split for the left and right hemisphere networks and the corresponding labels (y).\n",
    "\n",
    "# Step 1: Perform a joint split based on the indices\n",
    "# Generate the same train/test split indices for both hemispheres\n",
    "train_indices, test_indices = train_test_split(np.arange(sph_data_left.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split the data using these indices\n",
    "train_data_left = sph_data_left[train_indices]\n",
    "test_data_left = sph_data_left[test_indices]\n",
    "train_data_right = sph_data_left[train_indices]\n",
    "test_data_right = sph_data_left[test_indices]\n",
    "\n",
    "# Step 3: Split the target variable y using the same indices\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08afb48-4327-4dd2-8d68-f27fe02f9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Iteration 0, Loss: 0.00011646038910839707\n",
      "Iteration 50, Loss: 8.717192395124584e-05\n",
      "Iteration 0, Loss: 0.00011646038910839707\n",
      "Iteration 50, Loss: 8.717192395124584e-05\n",
      "Network number 2\n",
      "Iteration 0, Loss: 3.821830250672065e-05\n",
      "Iteration 50, Loss: 1.114604947360931e-05\n",
      "Iteration 0, Loss: 3.821830250672065e-05\n",
      "Iteration 50, Loss: 1.114604947360931e-05\n",
      "Network number 3\n",
      "Iteration 0, Loss: 8.042909030336887e-05\n",
      "Iteration 50, Loss: 0.018725931644439697\n",
      "Iteration 0, Loss: 8.042909030336887e-05\n",
      "Iteration 50, Loss: 0.018725931644439697\n",
      "Network number 4\n",
      "Iteration 0, Loss: 0.00013321891310624778\n",
      "Iteration 50, Loss: 0.03227923437952995\n",
      "Iteration 0, Loss: 0.00013321891310624778\n",
      "Iteration 50, Loss: 0.03227923437952995\n",
      "Network number 5\n",
      "Iteration 0, Loss: 1.7260834283661097e-05\n",
      "Iteration 50, Loss: 5.736729690397624e-06\n",
      "Iteration 0, Loss: 1.7260834283661097e-05\n",
      "Iteration 50, Loss: 5.736729690397624e-06\n",
      "Network number 6\n",
      "Iteration 0, Loss: 4.007687311968766e-05\n",
      "Iteration 50, Loss: 0.001302786055020988\n",
      "Iteration 0, Loss: 4.007687311968766e-05\n",
      "Iteration 50, Loss: 0.001302786055020988\n",
      "Network number 7\n",
      "Iteration 0, Loss: 1.626692210265901e-05\n",
      "Iteration 50, Loss: 5.213742497289786e-06\n",
      "Iteration 0, Loss: 1.626692210265901e-05\n",
      "Iteration 50, Loss: 5.213742497289786e-06\n",
      "Network number 8\n",
      "Iteration 0, Loss: 7.492541772080585e-05\n",
      "Iteration 50, Loss: 4.747776984004304e-05\n",
      "Iteration 0, Loss: 7.492541772080585e-05\n",
      "Iteration 50, Loss: 4.747776984004304e-05\n",
      "Network number 9\n",
      "Iteration 0, Loss: 8.205932681448758e-05\n",
      "Iteration 50, Loss: 5.333756053005345e-05\n",
      "Iteration 0, Loss: 8.205932681448758e-05\n",
      "Iteration 50, Loss: 5.333756053005345e-05\n",
      "Network number 10\n",
      "Iteration 0, Loss: 1.3114497960486915e-05\n",
      "Iteration 50, Loss: 3.292096153018065e-06\n",
      "Iteration 0, Loss: 1.3114497960486915e-05\n",
      "Iteration 50, Loss: 3.292096153018065e-06\n",
      "Network number 11\n",
      "Iteration 0, Loss: 7.0781243266537786e-06\n",
      "Iteration 50, Loss: 1.9823803540930385e-06\n",
      "Iteration 0, Loss: 7.0781243266537786e-06\n",
      "Iteration 50, Loss: 1.9823803540930385e-06\n",
      "Network number 12\n",
      "Iteration 0, Loss: 4.312336750444956e-05\n",
      "Iteration 50, Loss: 9.516240425000433e-06\n",
      "Iteration 0, Loss: 4.312336750444956e-05\n",
      "Iteration 50, Loss: 9.516240425000433e-06\n",
      "Network number 13\n",
      "Iteration 0, Loss: 3.5578700590122025e-06\n",
      "Iteration 50, Loss: 8.861593414621893e-07\n",
      "Iteration 0, Loss: 3.5578700590122025e-06\n",
      "Iteration 50, Loss: 8.861593414621893e-07\n",
      "Network number 14\n",
      "Iteration 0, Loss: 8.41218661662424e-06\n",
      "Iteration 50, Loss: 2.046412646450335e-06\n",
      "Iteration 0, Loss: 8.41218661662424e-06\n",
      "Iteration 50, Loss: 2.046412646450335e-06\n",
      "Network number 15\n",
      "Iteration 0, Loss: 4.2472718632780015e-05\n",
      "Iteration 50, Loss: 1.2055927982146386e-05\n",
      "Iteration 0, Loss: 4.2472718632780015e-05\n",
      "Iteration 50, Loss: 1.2055927982146386e-05\n",
      "Network number 16\n",
      "Iteration 0, Loss: 3.252228270866908e-05\n",
      "Iteration 50, Loss: 9.335852155345492e-06\n",
      "Iteration 0, Loss: 3.252228270866908e-05\n",
      "Iteration 50, Loss: 9.335852155345492e-06\n",
      "Network number 17\n",
      "Iteration 0, Loss: 0.00010372400720370933\n",
      "Iteration 50, Loss: 0.0316922664642334\n",
      "Iteration 0, Loss: 0.00010372400720370933\n",
      "Iteration 50, Loss: 0.0316922664642334\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "train_latent_space_left = np.zeros((train_data_left.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "train_latent_space_right = np.zeros((train_data_right.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range (train_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    train_autoencoder(autoencoders_left[i],  train_data_left[:,:,:,i], DEVICE, num_iterations=100)\n",
    "    train_autoencoder(autoencoders_right[i], train_data_right[:,:,:,i], DEVICE, num_iterations=100)\n",
    "\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i], train_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i],train_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    train_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    train_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872d059-7470-4089-bb2d-a04870211921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tr_lsp_lft = train_latent_space_left.reshape(train_latent_space_left.shape[0], -1)\n",
    "tr_lsp_rght = train_latent_space_right.reshape(train_latent_space_right.shape[0], -1)\n",
    "\n",
    "tr_lsp = np.concatenate ((tr_lsp_lft, tr_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835ee7c-d49a-4c35-a737-ef8ca4b9765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Network number 2\n",
      "Network number 3\n",
      "Network number 4\n",
      "Network number 5\n",
      "Network number 6\n",
      "Network number 7\n",
      "Network number 8\n",
      "Network number 9\n",
      "Network number 10\n",
      "Network number 11\n",
      "Network number 12\n",
      "Network number 13\n",
      "Network number 14\n",
      "Network number 15\n",
      "Network number 16\n",
      "Network number 17\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "test_latent_space_left = np.zeros((test_data_left.shape[0], 32, 64,   test_data_left.shape[-1]), dtype=np.float32)\n",
    "test_latent_space_right = np.zeros((test_data_right.shape[0], 32, 64, test_data_right.shape[-1]), dtype=np.float32)\n",
    "\n",
    "for i in range (test_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i],  test_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i], test_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    test_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    test_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2294f-a37c-463b-9263-24903357b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tst_lsp_lft = test_latent_space_left.reshape(test_latent_space_left.shape[0], -1)\n",
    "tst_lsp_rght = test_latent_space_right.reshape(test_latent_space_right.shape[0], -1)\n",
    "\n",
    "tst_lsp = np.concatenate((tst_lsp_lft, tst_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d370c-1a66-41c5-b9f2-882c0820ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Regresion final.\n",
    "model = Ridge()\n",
    "model.fit(tr_lsp, y_train)\n",
    "y_pred = model.predict(tst_lsp)\n",
    "scores_ = np.full((n_scores,), np.nan)\n",
    "for c in range(n_scores):\n",
    "    r, _ = pearsonr(y_pred[:, c], y_test[:, c])\n",
    "    scores_[c] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bec260-c759-40f5-9b84-3f8b975e0d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24433748920121828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "scores_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392987f-ef7b-4bc0-b1fd-e57b3dcd67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from data_processing import dataset_preprocessing, data_with_mask\n",
    "from sph_functions import interpolation_to_grid, hemisphere_to_spherical, spherical_to_hemisphere\n",
    "from plots_pavi import plot_sphere\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "from model import Autoencoder, initialize_model, train_autoencoder, extract_latent_space\n",
    "\n",
    "DIR = r'C:\\Github\\pavi_data'\n",
    "\n",
    "path_file   = os.path.join(DIR, '12_mean_sample_post.pt')\n",
    "path_jobs   = os.path.join(DIR, 'jobs.json')\n",
    "path_scores = os.path.join(DIR, 'scores_camcan.csv')\n",
    "n_job = 44\n",
    "\n",
    "\n",
    "net_number = None\n",
    "sh_orders = 32\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "X, y, seed = dataset_preprocessing(DEVICE, path_file, path_jobs, path_scores)\n",
    "\n",
    "vertices_left, vertices_right, network_left, network_right = data_with_mask(X, net_number)\n",
    "\n",
    "\n",
    "fancy_categories = [\n",
    "        'Benton faces',\n",
    "        'Fluid Intelligence',\n",
    "        'Emotion expression recognition',\n",
    "        'Famous faces',\n",
    "        'Hotel task',\n",
    "        'Picture priming',\n",
    "        'Proverb comprehension',\n",
    "        'Sentence comprehension (unacceptable error)',\n",
    "        'Sentence comprehension (reaction time)',\n",
    "        'Visual short term memory (mean)',\n",
    "        'Visual short term memory (precision)',\n",
    "        'Visual short term memory (doubt)',\n",
    "        'Visual short term memory (MSE)',\n",
    "    ]\n",
    "n_scores = len(fancy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f226bc-a72c-47b4-a990-76d99e7b48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh_order=32\n",
      "(218, 32258, 17)\n",
      "(218, 32258, 17)\n",
      "New shape:\n",
      "(218, 127, 254, 17)\n",
      "(218, 127, 254, 17)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "mesh_theta, sphere_src_left, sphere_src_right, sphere_dst = interpolation_to_grid(vertices_left, vertices_right, sh_orders)\n",
    "sph_data_left  = hemisphere_to_spherical(network_left, sphere_src_left, sphere_dst, sh_orders)\n",
    "sph_data_right = hemisphere_to_spherical(network_right, sphere_src_right, sphere_dst, sh_orders)\n",
    "\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)\n",
    "\n",
    "sph_data_left = sph_data_left.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_left.shape[-1])\n",
    "sph_data_right = sph_data_right.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_right.shape[-1])\n",
    "\n",
    "if isinstance(net_number, int):\n",
    "    plot_sphere(sph_data_left, net_number)\n",
    "    plot_sphere(sph_data_right, net_number)\n",
    "\n",
    "print(\"New shape:\")\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29e2f2-71eb-458d-93e3-dff88be8c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "autoencoders_left  = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "autoencoders_right = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "\n",
    "for ae_l, ae_r in zip(autoencoders_left, autoencoders_right):\n",
    "    initialize_model(ae_l)\n",
    "    initialize_model(ae_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d146bd-0c44-412a-95da-0f4f5c84da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Joint split for the left and right hemisphere networks and the corresponding labels (y).\n",
    "\n",
    "# Step 1: Perform a joint split based on the indices\n",
    "# Generate the same train/test split indices for both hemispheres\n",
    "train_indices, test_indices = train_test_split(np.arange(sph_data_left.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split the data using these indices\n",
    "train_data_left = sph_data_left[train_indices]\n",
    "test_data_left = sph_data_left[test_indices]\n",
    "train_data_right = sph_data_left[train_indices]\n",
    "test_data_right = sph_data_left[test_indices]\n",
    "\n",
    "# Step 3: Split the target variable y using the same indices\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf6924-7ec5-43ff-8f1c-dfab58541399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Iteration 0, Loss: 0.007351523265242577\n",
      "Iteration 50, Loss: 0.00703839398920536\n",
      "Iteration 0, Loss: 0.007351523265242577\n",
      "Iteration 50, Loss: 0.00703839398920536\n",
      "Network number 2\n",
      "Iteration 0, Loss: 0.0031178086064755917\n",
      "Iteration 50, Loss: 0.003041125601157546\n",
      "Iteration 0, Loss: 0.0031178086064755917\n",
      "Iteration 50, Loss: 0.003041125601157546\n",
      "Network number 3\n",
      "Iteration 0, Loss: 0.006489838473498821\n",
      "Iteration 50, Loss: 0.023547230288386345\n",
      "Iteration 0, Loss: 0.006489838473498821\n",
      "Iteration 50, Loss: 0.023547230288386345\n",
      "Network number 4\n",
      "Iteration 0, Loss: 0.006615982856601477\n",
      "Iteration 50, Loss: 0.0902128517627716\n",
      "Iteration 0, Loss: 0.006615982856601477\n",
      "Iteration 50, Loss: 0.0902128517627716\n",
      "Network number 5\n",
      "Iteration 0, Loss: 0.003936176188290119\n",
      "Iteration 50, Loss: 0.003816701238974929\n",
      "Iteration 0, Loss: 0.003936176188290119\n",
      "Iteration 50, Loss: 0.003816701238974929\n",
      "Network number 6\n",
      "Iteration 0, Loss: 0.005872378591448069\n",
      "Iteration 50, Loss: 0.007325686048716307\n",
      "Iteration 0, Loss: 0.005872378591448069\n",
      "Iteration 50, Loss: 0.007325686048716307\n",
      "Network number 7\n",
      "Iteration 0, Loss: 0.0029436638578772545\n",
      "Iteration 50, Loss: 0.0028797287959605455\n",
      "Iteration 0, Loss: 0.0029436638578772545\n",
      "Iteration 50, Loss: 0.0028797287959605455\n",
      "Network number 8\n",
      "Iteration 0, Loss: 0.004341141786426306\n",
      "Iteration 50, Loss: 0.004232908599078655\n",
      "Iteration 0, Loss: 0.004341141786426306\n",
      "Iteration 50, Loss: 0.004232908599078655\n",
      "Network number 9\n",
      "Iteration 0, Loss: 0.004555883351713419\n",
      "Iteration 50, Loss: 0.004393798299133778\n",
      "Iteration 0, Loss: 0.004555883351713419\n",
      "Iteration 50, Loss: 0.004393798299133778\n",
      "Network number 10\n",
      "Iteration 0, Loss: 0.003014196176081896\n",
      "Iteration 50, Loss: 0.0029445895925164223\n",
      "Iteration 0, Loss: 0.003014196176081896\n",
      "Iteration 50, Loss: 0.0029445895925164223\n",
      "Network number 11\n",
      "Iteration 0, Loss: 0.00195322185754776\n",
      "Iteration 50, Loss: 0.0019250124460086226\n",
      "Iteration 0, Loss: 0.00195322185754776\n",
      "Iteration 50, Loss: 0.0019250124460086226\n",
      "Network number 12\n",
      "Iteration 0, Loss: 0.0028282583225518465\n",
      "Iteration 50, Loss: 0.0027594685088843107\n",
      "Iteration 0, Loss: 0.0028282583225518465\n",
      "Iteration 50, Loss: 0.0027594685088843107\n",
      "Network number 13\n",
      "Iteration 0, Loss: 0.0010421903571113944\n",
      "Iteration 50, Loss: 0.0010330459335818887\n",
      "Iteration 0, Loss: 0.0010421903571113944\n",
      "Iteration 50, Loss: 0.0010330459335818887\n",
      "Network number 14\n",
      "Iteration 0, Loss: 0.0024879546836018562\n",
      "Iteration 50, Loss: 0.0024506549816578627\n",
      "Iteration 0, Loss: 0.0024879546836018562\n",
      "Iteration 50, Loss: 0.0024506549816578627\n",
      "Network number 15\n",
      "Iteration 0, Loss: 0.0035197685938328505\n",
      "Iteration 50, Loss: 0.003436808008700609\n",
      "Iteration 0, Loss: 0.0035197685938328505\n",
      "Iteration 50, Loss: 0.003436808008700609\n",
      "Network number 16\n",
      "Iteration 0, Loss: 0.0046994187869131565\n",
      "Iteration 50, Loss: 0.004564543720334768\n",
      "Iteration 0, Loss: 0.0046994187869131565\n",
      "Iteration 50, Loss: 0.004564543720334768\n",
      "Network number 17\n",
      "Iteration 0, Loss: 0.007263112347573042\n",
      "Iteration 50, Loss: 0.039598654955625534\n",
      "Iteration 0, Loss: 0.007263112347573042\n",
      "Iteration 50, Loss: 0.039598654955625534\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "train_latent_space_left = np.zeros((train_data_left.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "train_latent_space_right = np.zeros((train_data_right.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range (train_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    train_autoencoder(autoencoders_left[i],  train_data_left[:,:,:,i], DEVICE, num_iterations=100)\n",
    "    train_autoencoder(autoencoders_right[i], train_data_right[:,:,:,i], DEVICE, num_iterations=100)\n",
    "\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i], train_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i],train_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    train_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    train_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b12c29-2aac-4fd9-80b6-59dd7783ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tr_lsp_lft = train_latent_space_left.reshape(train_latent_space_left.shape[0], -1)\n",
    "tr_lsp_rght = train_latent_space_right.reshape(train_latent_space_right.shape[0], -1)\n",
    "\n",
    "tr_lsp = np.concatenate ((tr_lsp_lft, tr_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b064f0-9a4f-4f81-a356-fef54df961b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Network number 2\n",
      "Network number 3\n",
      "Network number 4\n",
      "Network number 5\n",
      "Network number 6\n",
      "Network number 7\n",
      "Network number 8\n",
      "Network number 9\n",
      "Network number 10\n",
      "Network number 11\n",
      "Network number 12\n",
      "Network number 13\n",
      "Network number 14\n",
      "Network number 15\n",
      "Network number 16\n",
      "Network number 17\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "test_latent_space_left = np.zeros((test_data_left.shape[0], 32, 64,   test_data_left.shape[-1]), dtype=np.float32)\n",
    "test_latent_space_right = np.zeros((test_data_right.shape[0], 32, 64, test_data_right.shape[-1]), dtype=np.float32)\n",
    "\n",
    "for i in range (test_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i],  test_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i], test_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    test_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    test_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417eeb4-ca17-4516-988c-079eb162c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tst_lsp_lft = test_latent_space_left.reshape(test_latent_space_left.shape[0], -1)\n",
    "tst_lsp_rght = test_latent_space_right.reshape(test_latent_space_right.shape[0], -1)\n",
    "\n",
    "tst_lsp = np.concatenate((tst_lsp_lft, tst_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62dc10c-4f71-468d-80d4-65fc9d83e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Regresion final.\n",
    "model = Ridge()\n",
    "model.fit(tr_lsp, y_train)\n",
    "y_pred = model.predict(tst_lsp)\n",
    "scores_ = np.full((n_scores,), np.nan)\n",
    "for c in range(n_scores):\n",
    "    r, _ = pearsonr(y_pred[:, c], y_test[:, c])\n",
    "    scores_[c] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b281715-780d-4868-bea4-a8dc4cfb38b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2486250689781005"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "scores_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f6cc2-dfc7-4c99-a584-449ea9a72893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from data_processing import dataset_preprocessing, data_with_mask\n",
    "from sph_functions import interpolation_to_grid, hemisphere_to_spherical\n",
    "from plots_pavi import plot_sphere\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "from model import Autoencoder, initialize_model, train_autoencoder, extract_latent_space\n",
    "\n",
    "DIR = r'C:\\Github\\pavi_data'\n",
    "\n",
    "path_file   = os.path.join(DIR, '12_mean_sample_post.pt')\n",
    "path_jobs   = os.path.join(DIR, 'jobs.json')\n",
    "path_scores = os.path.join(DIR, 'scores_camcan.csv')\n",
    "n_job = 44\n",
    "\n",
    "\n",
    "net_number = None\n",
    "sh_orders = 80\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "X, y, seed = dataset_preprocessing(DEVICE, path_file, path_jobs, path_scores)\n",
    "\n",
    "vertices_left, vertices_right, network_left, network_right = data_with_mask(X, net_number)\n",
    "\n",
    "\n",
    "fancy_categories = [\n",
    "        'Benton faces',\n",
    "        'Fluid Intelligence',\n",
    "        'Emotion expression recognition',\n",
    "        'Famous faces',\n",
    "        'Hotel task',\n",
    "        'Picture priming',\n",
    "        'Proverb comprehension',\n",
    "        'Sentence comprehension (unacceptable error)',\n",
    "        'Sentence comprehension (reaction time)',\n",
    "        'Visual short term memory (mean)',\n",
    "        'Visual short term memory (precision)',\n",
    "        'Visual short term memory (doubt)',\n",
    "        'Visual short term memory (MSE)',\n",
    "    ]\n",
    "n_scores = len(fancy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539927bd-58d8-41dc-9d7b-42069286d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh_order=80\n",
      "(218, 32258, 17)\n",
      "(218, 32258, 17)\n",
      "New shape:\n",
      "(218, 127, 254, 17)\n",
      "(218, 127, 254, 17)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "mesh_theta, sphere_src_left, sphere_src_right, sphere_dst = interpolation_to_grid(vertices_left, vertices_right, sh_orders)\n",
    "sph_data_left  = hemisphere_to_spherical(network_left, sphere_src_left, sphere_dst, sh_orders)\n",
    "sph_data_right = hemisphere_to_spherical(network_right, sphere_src_right, sphere_dst, sh_orders)\n",
    "\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)\n",
    "\n",
    "sph_data_left = sph_data_left.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_left.shape[-1])\n",
    "sph_data_right = sph_data_right.reshape(-1,mesh_theta.shape[0], mesh_theta.shape[1],network_right.shape[-1])\n",
    "\n",
    "if isinstance(net_number, int):\n",
    "    plot_sphere(sph_data_left, net_number)\n",
    "    plot_sphere(sph_data_right, net_number)\n",
    "\n",
    "print(\"New shape:\")\n",
    "print(sph_data_left.shape)\n",
    "print(sph_data_right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3880-02be-4976-9905-91747f2fd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "autoencoders_left  = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "autoencoders_right = [Autoencoder(127, 254, kernel=30).to(DEVICE) for _ in range(sph_data_left.shape[-1])]\n",
    "\n",
    "for ae_l, ae_r in zip(autoencoders_left, autoencoders_right):\n",
    "    initialize_model(ae_l)\n",
    "    initialize_model(ae_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72855bd-5d66-4679-8dac-0e0ca837c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Joint split for the left and right hemisphere networks and the corresponding labels (y).\n",
    "\n",
    "# Step 1: Perform a joint split based on the indices\n",
    "# Generate the same train/test split indices for both hemispheres\n",
    "train_indices, test_indices = train_test_split(np.arange(sph_data_left.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split the data using these indices\n",
    "train_data_left = sph_data_left[train_indices]\n",
    "test_data_left = sph_data_left[test_indices]\n",
    "train_data_right = sph_data_left[train_indices]\n",
    "test_data_right = sph_data_left[test_indices]\n",
    "\n",
    "# Step 3: Split the target variable y using the same indices\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806bb03-24ad-4e38-989b-430bad5564b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Iteration 0, Loss: 0.10739010572433472\n",
      "Iteration 50, Loss: 0.10279100388288498\n",
      "Iteration 0, Loss: 0.10739010572433472\n",
      "Iteration 50, Loss: 0.10279100388288498\n",
      "Network number 2\n",
      "Iteration 0, Loss: 0.055353179574012756\n",
      "Iteration 50, Loss: 0.05329129844903946\n",
      "Iteration 0, Loss: 0.055353179574012756\n",
      "Iteration 50, Loss: 0.05329129844903946\n",
      "Network number 3\n",
      "Iteration 0, Loss: 0.10854646563529968\n",
      "Iteration 50, Loss: 0.10400619357824326\n",
      "Iteration 0, Loss: 0.10854646563529968\n",
      "Iteration 50, Loss: 0.10400619357824326\n",
      "Network number 4\n",
      "Iteration 0, Loss: 0.10516277700662613\n",
      "Iteration 50, Loss: 0.11232051253318787\n",
      "Iteration 0, Loss: 0.10516277700662613\n",
      "Iteration 50, Loss: 0.11232051253318787\n",
      "Network number 5\n",
      "Iteration 0, Loss: 0.07743297517299652\n",
      "Iteration 50, Loss: 0.07389683276414871\n",
      "Iteration 0, Loss: 0.07743297517299652\n",
      "Iteration 50, Loss: 0.07389683276414871\n",
      "Network number 6\n",
      "Iteration 0, Loss: 0.10648210346698761\n",
      "Iteration 50, Loss: 0.1010470762848854\n",
      "Iteration 0, Loss: 0.10648210346698761\n",
      "Iteration 50, Loss: 0.1010470762848854\n",
      "Network number 7\n",
      "Iteration 0, Loss: 0.05023215338587761\n",
      "Iteration 50, Loss: 0.04835037887096405\n",
      "Iteration 0, Loss: 0.05023215338587761\n",
      "Iteration 50, Loss: 0.04835037887096405\n",
      "Network number 8\n",
      "Iteration 0, Loss: 0.07346554100513458\n",
      "Iteration 50, Loss: 0.07074210047721863\n",
      "Iteration 0, Loss: 0.07346554100513458\n",
      "Iteration 50, Loss: 0.07074210047721863\n",
      "Network number 9\n",
      "Iteration 0, Loss: 0.07331272214651108\n",
      "Iteration 50, Loss: 0.07051956653594971\n",
      "Iteration 0, Loss: 0.07331272214651108\n",
      "Iteration 50, Loss: 0.07051956653594971\n",
      "Network number 10\n",
      "Iteration 0, Loss: 0.05562097206711769\n",
      "Iteration 50, Loss: 0.05340779945254326\n",
      "Iteration 0, Loss: 0.05562097206711769\n",
      "Iteration 50, Loss: 0.05340779945254326\n",
      "Network number 11\n",
      "Iteration 0, Loss: 0.042477965354919434\n",
      "Iteration 50, Loss: 0.04049816355109215\n",
      "Iteration 0, Loss: 0.042477965354919434\n",
      "Iteration 50, Loss: 0.04049816355109215\n",
      "Network number 12\n",
      "Iteration 0, Loss: 0.049773216247558594\n",
      "Iteration 50, Loss: 0.04782086983323097\n",
      "Iteration 0, Loss: 0.049773216247558594\n",
      "Iteration 50, Loss: 0.04782086983323097\n",
      "Network number 13\n",
      "Iteration 0, Loss: 0.022398272529244423\n",
      "Iteration 50, Loss: 0.021503906697034836\n",
      "Iteration 0, Loss: 0.022398272529244423\n",
      "Iteration 50, Loss: 0.021503906697034836\n",
      "Network number 14\n",
      "Iteration 0, Loss: 0.05379338562488556\n",
      "Iteration 50, Loss: 0.05125417932868004\n",
      "Iteration 0, Loss: 0.05379338562488556\n",
      "Iteration 50, Loss: 0.05125417932868004\n",
      "Network number 15\n",
      "Iteration 0, Loss: 0.06333884596824646\n",
      "Iteration 50, Loss: 0.060965344309806824\n",
      "Iteration 0, Loss: 0.06333884596824646\n",
      "Iteration 50, Loss: 0.060965344309806824\n",
      "Network number 16\n",
      "Iteration 0, Loss: 0.07616087794303894\n",
      "Iteration 50, Loss: 0.07222513109445572\n",
      "Iteration 0, Loss: 0.07616087794303894\n",
      "Iteration 50, Loss: 0.07222513109445572\n",
      "Network number 17\n",
      "Iteration 0, Loss: 0.11005108058452606\n",
      "Iteration 50, Loss: 0.10611468553543091\n",
      "Iteration 0, Loss: 0.11005108058452606\n",
      "Iteration 50, Loss: 0.10611468553543091\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "train_latent_space_left = np.zeros((train_data_left.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "train_latent_space_right = np.zeros((train_data_right.shape[0], 32, 64, train_data_left.shape[-1]), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range (train_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    train_autoencoder(autoencoders_left[i],  train_data_left[:,:,:,i], DEVICE, num_iterations=100)\n",
    "    train_autoencoder(autoencoders_right[i], train_data_right[:,:,:,i], DEVICE, num_iterations=100)\n",
    "\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i], train_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i],train_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    train_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    train_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9ecd7-6b09-4feb-9974-b69174bdb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tr_lsp_lft = train_latent_space_left.reshape(train_latent_space_left.shape[0], -1)\n",
    "tr_lsp_rght = train_latent_space_right.reshape(train_latent_space_right.shape[0], -1)\n",
    "\n",
    "tr_lsp = np.concatenate ((tr_lsp_lft, tr_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81031481-0be3-4246-805d-787a211c1296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network number 1\n",
      "Network number 2\n",
      "Network number 3\n",
      "Network number 4\n",
      "Network number 5\n",
      "Network number 6\n",
      "Network number 7\n",
      "Network number 8\n",
      "Network number 9\n",
      "Network number 10\n",
      "Network number 11\n",
      "Network number 12\n",
      "Network number 13\n",
      "Network number 14\n",
      "Network number 15\n",
      "Network number 16\n",
      "Network number 17\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "test_latent_space_left = np.zeros((test_data_left.shape[0], 32, 64,   test_data_left.shape[-1]), dtype=np.float32)\n",
    "test_latent_space_right = np.zeros((test_data_right.shape[0], 32, 64, test_data_right.shape[-1]), dtype=np.float32)\n",
    "\n",
    "for i in range (test_data_left.shape[-1]):\n",
    "    print (f\"Network number {1+i}\")\n",
    "    lsp_left  = extract_latent_space(autoencoders_left[i],  test_data_left[:,:,:,i], DEVICE)\n",
    "    lsp_right = extract_latent_space(autoencoders_right[i], test_data_right[:,:,:,i], DEVICE)\n",
    "\n",
    "    test_latent_space_left[:, :, :, i]  = lsp_left\n",
    "    test_latent_space_right[:, :, :, i] = lsp_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdebac9-1d34-4197-9d8e-0992af7314fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "tst_lsp_lft = test_latent_space_left.reshape(test_latent_space_left.shape[0], -1)\n",
    "tst_lsp_rght = test_latent_space_right.reshape(test_latent_space_right.shape[0], -1)\n",
    "\n",
    "tst_lsp = np.concatenate((tst_lsp_lft, tst_lsp_rght), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e2b9e-9630-40e9-816e-9f6545425310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Regresion final.\n",
    "model = Ridge()\n",
    "model.fit(tr_lsp, y_train)\n",
    "y_pred = model.predict(tst_lsp)\n",
    "scores_ = np.full((n_scores,), np.nan)\n",
    "for c in range(n_scores):\n",
    "    r, _ = pearsonr(y_pred[:, c], y_test[:, c])\n",
    "    scores_[c] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faabfbe-1cf4-4475-ab8f-84aed703a420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24300207164287205"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "scores_.mean()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
